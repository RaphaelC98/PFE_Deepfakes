{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"New_temporal_dataset.ipynb","provenance":[],"authorship_tag":"ABX9TyOwxZvgErF0uhPSeHXxLqR9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A5fVXntnnfE6","executionInfo":{"status":"ok","timestamp":1623676953186,"user_tz":-120,"elapsed":16961,"user":{"displayName":"Raphael Catanese","photoUrl":"","userId":"01157269626718155422"}},"outputId":"cd52a44a-fc1a-4389-cae7-1e9a735ec0a5"},"source":["from google.colab import drive\n","drive.mount(\"/content/MyDrive/\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/MyDrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GbNUkk0Mpi1Z","executionInfo":{"status":"ok","timestamp":1623676984336,"user_tz":-120,"elapsed":30051,"user":{"displayName":"Raphael Catanese","photoUrl":"","userId":"01157269626718155422"}},"outputId":"60ef7fa9-b932-493c-f175-9bad539721e3"},"source":["!pip install face_recognition"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting face_recognition\n","  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n","Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Collecting face-recognition-models>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n","\u001b[K     |████████████████████████████████| 100.2MB 60kB/s \n","\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566184 sha256=459cfb5b9266cabfef94101c584d9305f1aa2ff471ba90458f189281d406f8f7\n","  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face-recognition\n","Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uSbtQt02pi36","executionInfo":{"status":"ok","timestamp":1623676984336,"user_tz":-120,"elapsed":5,"user":{"displayName":"Raphael Catanese","photoUrl":"","userId":"01157269626718155422"}}},"source":["dir_path = \"/content/MyDrive/MyDrive/PFE_Deepfakes/datasets/DFDC/\" \n","train_path = \"datasets/DFDC/temporal/train\"\n","validation_path = \"datasets/DFDC/temporal/validation\"\n","test_path = \"datasets/DFDC/temporal/test\""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PZ7q-U9KrIbS","executionInfo":{"status":"ok","timestamp":1623676984337,"user_tz":-120,"elapsed":5,"user":{"displayName":"Raphael Catanese","photoUrl":"","userId":"01157269626718155422"}},"outputId":"943e49df-b03b-40a7-f018-94851fd85ec3"},"source":["cd /content/MyDrive/MyDrive/PFE_Deepfakes"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/MyDrive/MyDrive/PFE_Deepfakes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9nQoCpqfrEus","executionInfo":{"status":"ok","timestamp":1623677037061,"user_tz":-120,"elapsed":9165,"user":{"displayName":"Raphael Catanese","photoUrl":"","userId":"01157269626718155422"}}},"source":["import os\n","import json\n","import numpy as np\n","import time\n","import face_recognition\n","from df_code.CViT_main.CViT_main.helpers import helpers_face_extract_1, helpers_read_video_1, blazeface\n","import cv2\n","import shutil\n","from time import perf_counter\n","import sys\n","import torch\n","from df_code.CViT_main.CViT_main.helpers.blazeface import BlazeFace"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ErlQjlKlrNLR"},"source":["#data\n","metadata = json.load(open('datasets/DFDC/dfdc_train_part_00/dfdc_train_part_0/metadata.json'))\n","fake=[]\n","original=[]\n","    \n","for file_dp in metadata :\n","  print( metadata[file_dp])\n","  print(('original' in metadata[file_dp]) and (metadata[file_dp]['original'] not in original) and (metadata[file_dp]['original'] is not None))\n","  if (('original' in metadata[file_dp]) and (metadata[file_dp]['original'] not in original) and (metadata[file_dp]['original'] is not None)):\n","            original.append(metadata[file_dp]['original'])\n","            fake.append(file_dp)\n","print(fake)\n","print(original)\n","print(np.array([[i, j] for i, j in zip(fake, original)]).ravel())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UoribK5api6Z"},"source":["\n","\n","# code used to extract DFDC dataset\n","\n","\n","  \n","# load DFDC json\n","def load_metadata(dir_path):\n","    metafile = dir_path+'/metadata.json'\n","     \n","    if os.path.isfile(metafile):\n","        with open(metafile) as data_file:\n","            data = json.load(data_file)\n","    else:\n","        return 1\n","    \n","    return data\n","\n","def extract_face(dir_path):\n","    print(\"beginning...\")\n","    for item in sorted(os.listdir(dir_path)): # iterate over the 49 train part of DFDC\n","        print(item)\n","        \n","        file_num = int(item[16:]) #by default the destination is the train_path\n","        destination = train_path\n","        \n","        if (file_num > 34 and file_num <46): #but part 35 to 45 will go to the validation set\n","            destination = validation_path \n","        \n","        if (file_num > 45): #and part 46 to 49 to test set\n","            destination = test_path\n","        \n","        meta_full_path = os.path.join(dir_path, item) #meta_full_path is the path to each of the 49 part of the original dataset\n","        \n","        if os.path.isdir(meta_full_path) <= 3 : #there could be other files in our dir_path that are not our folders with the train data\n","            data = load_metadata(meta_full_path+'/dfdc_train_part_'+str(file_num))\n","            print(meta_full_path+'/dfdc_train_part_'+str(file_num))\n","            \n","            if data != 1: #if the metadata files exists (look the returns of the above function)\n","                \n","                if not os.path.exists(destination+str(file_num)): #check if exists else creates directory\n","                    os.makedirs(destination+str(file_num))\n","                \n","                if not os.path.isfile(destination+str(file_num)+'/metadata.json'): #check if exists else creates metadata\n","                    shutil.copy2(dir_path+'/'+item+'/dfdc_train_part_'+str(file_num)+'/metadata.json', destination+str(file_num)+'/metadata.json')\n","                  \n","                filtered_files = filter_unique_files(data)\n","                \n","                for filename in filtered_files:\n","                    # check if the file name is found in metadata, and its label\n","                    if filename.endswith(\".mp4\") and os.path.isfile(dir_path+'/'+item+'/dfdc_train_part_'+str(file_num)+'/'+filename):\n","                        label = data[filename]['label'].lower()\n","                        # append fake video names with their corresponding real video names\n","                        original = ''\n","                        if data[filename]['label'].lower() == 'fake':\n","                            original = '_'+data[filename]['original'][:-4]\n","                        image_path = destination+str(file_num)+'/'+label\n","                        if not os.path.exists(image_path):\n","                            os.makedirs(image_path)\n","                            \n","                        process_video(dir_path+'/'+item+'/dfdc_train_part_'+str(file_num)+'/'+filename, filename, image_path, original)\n","\n","# access video\n","def process_video(video_path, filename, image_path, original):\n","    gpu = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    facedet = BlazeFace().to(gpu)\n","    facedet.load_weights(\"df_code/CViT_main/CViT_main/helpers/blazeface.pth\")\n","    facedet.load_anchors(\"df_code/CViT_main/CViT_main/helpers/anchors.npy\")\n","    _ = facedet.train(False)\n","    \n","    from df_code.CViT_main.CViT_main.helpers.helpers_read_video_1 import VideoReader\n","    from df_code.CViT_main.CViT_main.helpers.helpers_face_extract_1 import FaceExtractor\n","\n","    frames_per_video = 10\n","     \n","    video_reader = VideoReader()\n","    video_read_fn = lambda x: video_reader.read_random_frames(x, num_frames=frames_per_video)\n","    face_extractor = FaceExtractor(video_read_fn, facedet)\n","    \n","    faces = face_extractor.process_video(video_path)\n","    # Only look at one face per frame.\n","    face_extractor.keep_only_best_face(faces)\n","    n = 0\n","    for frame_data in faces:\n","        for face in frame_data[\"faces\"]:\n","            face_locations = face_recognition.face_locations(face)\n","            for face_location in face_locations:\n","            \n","                top, right, bottom, left = face_location\n","                face_image = face[top:bottom, left:right]\n","                resized_face = cv2.resize(face_image, (224, 224), interpolation=cv2.INTER_AREA)\n","                resized_face = cv2.cvtColor(resized_face, cv2.COLOR_RGB2BGR)\n","            \n","                cv2.imwrite(image_path+\"/\"+filename[:-4]+original+\"_\"+str(n)+\".jpg\",resized_face, [int(cv2.IMWRITE_JPEG_QUALITY), 85])\n","                \n","                n += 1\n","\n","def filter_unique_files(metadata):\n","    fake=[]\n","    original=[]\n","    \n","    for file_dp in metadata:\n","        if (('original' in metadata[file_dp]) and (metadata[file_dp]['original'] not in original) and (metadata[file_dp]['original'] is not None)): #allows to take only one fake per original video (real)\n","            original.append(metadata[file_dp]['original'])\n","            fake.append(file_dp)\n","    return np.array([[i, j] for i, j in zip(fake, original)]).ravel()\n","\n","start_time = perf_counter()\n","extract_face(dir_path)\n","end_time = perf_counter()\n","print(\"--- %s seconds ---\" % (end_time - start_time))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UbiVaQd0pi9B"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hu1EELvupi_h"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rM00NyTrpjCK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDPcbD3JpjEf"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4VslPitpjG4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AEiSOHxjpjJc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WvOfxwubpjL5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rq3l9qPhpjOR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6A5pae35pjQp"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VPF5aLmOpjSy"},"source":[""],"execution_count":null,"outputs":[]}]}